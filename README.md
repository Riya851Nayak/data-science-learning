- Pandas: Sorting and GroupBy operations
# Data Science Learning

This repository contains my daily practice and learning of **Data Science using Pandas**.

## ðŸ“… Day-wise Progress

### Day 3 â€“ Sorting & GroupBy
- Learned sorting data using `sort_values()`
- Used `groupby()` for data aggregation
- Performed basic analysis on tabular data

### Day 4 â€“ Data Cleaning
- Handling missing values using `dropna()`
- Understanding `df.info()` and data types
- Basic data cleaning techniques in Pandas

### Day 5 â€“ Exploratory Data Analysis (EDA)
- Performed basic EDA using Pandas
- Used `describe()` for statistical summary
- Analyzed marks distribution
- Visualized data using Matplotlib (histogram, bar chart, line plot)
- Derived basic insights from data

## Day 8 â€“ Machine Learning
- Built a Linear Regression model
- Predicted writing score using math & reading scores
- Evaluated model using Mean Absolute Error (MAE)

## Day 08 â€“ Student Performance Prediction (ML)
### Objective
Build a machine learning model to predict students' writing scores based on academic and demographic features.
### Model Used
- Linear Regression
### Evaluation Metrics
- Mean Squared Error (MSE): ~23.66
- RÂ² Score: ~0.90

### Day 11 â€“ Decision Tree Regression
- Objective: Predict writing score
- Algorithm: Decision Tree Regressor
- Features used: math score, reading score
- Evaluation metrics: MAE, RÂ² Score
- Overfitting handled using max_depth

  ## Day 12 â€“ Random Forest Regression
- Implemented Random Forest Regressor
- Compared performance using MAE and R2 Score
- Analyzed feature importance
- Observed reading score as the most influential feature

###Day 13 â€“ Model Evaluation & Comparison**
- Train RÂ² > Test RÂ²
- Decision Tree:more overfit hota hai
- Random Forest:stable & accurate
- Random Forest > Decision Tree

 ### Day 14 â€“ Hyperparameter Tuning
- Applied GridSearchCV on Random Forest Regressor
- Tuned parameters: n_estimators, max_depth, min_samples_split, min_samples_leaf
- Model performance improved after tuning
- MAE decreased and RÂ² score increased
- Overfitting reduced and generalization improved

### Visualization
The scatter plot of **Actual vs Predicted Writing Score** shows that most points lie close to the diagonal line, indicating that the model predictions are very close to the actual values and the model performs well.
### Conclusion
1.The model successfully learns the relationship between input features and writing scores and provides accurate predictions.
2.The model performs well as residuals are randomly distributed around zero.
MAE value shows the average prediction error is low.


## ðŸ›  Tools Used
- Python
- Pandas
- Jupyter Notebook
- GitHub

## Skill Covering
- Data Cleaning
- Handling Missing Values
- Sorting & GroupBy
- Exploratory Data Analysis (EDA)
- Data Visualization (Matplotlib)
- Added MAE metric
 -Performed residual analysis

## ðŸš€ Goal
To build a strong foundation in **Data Science** through daily hands-on practice.

---
âœ¨ Learning step by step, one day at a time.






